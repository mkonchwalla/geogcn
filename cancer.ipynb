{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python373jvsc74a57bd0cf3f37f54f5604e82cfd3e9e70e60b218afb28f715a34c084c12da51e5a1efbd",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtxakFlbq8bX",
        "outputId": "0146a0e0-607b-45fe-e60f-d705fd903620"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci5Amu-qsGDi"
      },
      "source": [
        "path = 'gdrive/MyDrive/pytorch_geo_gcn/'\n",
        "path = ''"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9qiLuqCGS50q",
        "outputId": "0e3a4541-a7c4-45d5-e1c9-155f3ccf962e"
      },
      "source": [
        "# !pip install torch==version\n",
        "TORCH_version = torch.__version__\n",
        "# TORCH = format_pytorch_version(TORCH_version)\n",
        "torch.__version__"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zzJRqg7sRaW",
        "outputId": "9c14e2b5-45d6-474e-b66a-d4d2c7c0a679"
      },
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "print(torch.version.cuda,TORCH)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.1 1.8.1\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.1+cu101.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/91/26/f2f0767a0e72c38d5d17f53117deb8aaafaf58f4ad658cee56cd5158c979/torch_scatter-2.0.6.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDht61_atH7l"
      },
      "source": [
        "Defining the GCN class/layer in the following cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inM98vpVtOdA"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "from  torch_geometric.nn import GCNConv, Sequential\n",
        "\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, num_feat, num_hid, num_class,dropout):\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "        self.gc1 = GCNConv(num_feat, num_hid)\n",
        "        self.gc2 = GCNConv(num_hid, num_hid)\n",
        "        # self.gc3 = GCNConv(num_hid, num_hid)\n",
        "        self.gc4 = GCNConv(num_hid, num_class)\n",
        "        # self.gc5 = GCNConv(num_hid, num_class)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self,x,edge_index,edge_weight): \n",
        "        x= F.relu(self.gc1(x=x, edge_index= edge_index , edge_weight = edge_weight))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.sigmoid(self.gc2(x=x.float(),edge_index= edge_index, edge_weight= edge_weight))\n",
        "        # x = F.dropout(x, self.dropout, training=self.training)\n",
        "        # x = torch.sigmoid(self.gc3(x=x.float(),edge_index= edge_index, edge_weight= edge_weight))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = self.gc4(x=x.float(),edge_index= edge_index, edge_weight= edge_weight)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvVak0cBtbpP"
      },
      "source": [
        "The next cell contains some utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw02G8V5tPFJ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "from scipy import stats\n",
        "import os\n",
        "import time\n",
        "from sklearn import preprocessing, feature_extraction, model_selection\n",
        "from copy import deepcopy\n",
        "from IPython.display import display, HTML\n",
        "import scipy.sparse\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.spatial import KDTree\n",
        "import networkx as nx\n",
        "from torch import LongTensor\n",
        "from torch import int64\n",
        "from torch import tensor\n",
        "\n",
        "\n",
        "\n",
        "def get_labels(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: i for i,c in enumerate(classes)}\n",
        "    labels = np.array([classes_dict[i] for i in labels])\n",
        "    return labels\n",
        "\n",
        "\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize matrix - Unchanged from Kipfs\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "\n",
        "def distance_matrix(cutoff, points_1, points_2=None, output='dict'):\n",
        "    \n",
        "    \"\"\"\n",
        "    This function computes a distance matrix between points in 'points_1' and 'points_2'\n",
        "    that are within 'cutoff' of each other.\n",
        "    \n",
        "    ***Input\n",
        "    cutoff   : the distance cutoff\n",
        "    points_1 : a numpy array of coordinates\n",
        "    points_2 : a numpy array of coordinates\n",
        "    output   : form of output.\n",
        "    ***Output\n",
        "            'dict': (default) is a dictionary with every pair of points as the keys\n",
        "                                 and the distance as the value.\n",
        "            'coo_matrix', 'dok_matrix', 'ndarray'\n",
        "    \"\"\"\n",
        "    \n",
        "    tree1 = scipy.spatial.cKDTree(points_1, leafsize=16)\n",
        "    if points_2 is None:\n",
        "        points_2 = points_1\n",
        "    tree2 = scipy.spatial.cKDTree(points_2,leafsize=16)\n",
        "    \n",
        "    distances = tree1.sparse_distance_matrix(tree2, cutoff, output_type=output)\n",
        "    return distances\n",
        "\n",
        "\n",
        "\n",
        "def from_scipy_sparse_matrix(A):\n",
        "    r\"\"\"Converts a scipy sparse matrix to edge indices and edge attributes.\n",
        "\n",
        "    Args:\n",
        "        A (scipy.sparse): A sparse matrix.\n",
        "    \"\"\"\n",
        "    A = A.tocoo()\n",
        "    row = torch.from_numpy(A.row).to(torch.long)\n",
        "    col = torch.from_numpy(A.col).to(torch.long)\n",
        "    edge_index = torch.stack([row, col], dim=0)\n",
        "    edge_weight = torch.from_numpy(A.data)\n",
        "    return edge_index, edge_weight\n",
        "\n",
        "\n",
        "def convert_sparse_matrix_to_sparse_tensor(coo):\n",
        "    values = coo.data\n",
        "    indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = coo.shape\n",
        "    return torch.sparse.FloatTensor(i, v, torch.Size(shape)).to_dense()\n",
        "\n",
        "def load_data_adjacency(roi='BRAC4002.3c_ROI3_MRTX.', cutoff= 25, output='dict',label_output='Domain'):\n",
        "\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    roi - required reigon of interest: \n",
        "    Valid  ROI's are: ['BRAC3495.3f_ROI1_Cont_crop1.', 'BRAC3495.3f_ROI1_Cont_crop2.',\n",
        "        'BRAC3326.4e_ROI1_Cont_crop1.', 'BRAC3438.6f_ROI1_Cont.',\n",
        "        'BRAC3438.6f_ROI2_Cont.', 'BRAC3438.6f_ROI3_Cont.', 'BRAC3529.2d_ROI1_MRTX.', 'BRAC4002.3c_ROI2_MRTX_crop1.',\n",
        "        'BRAC4002.3c_ROI2_MRTX_crop2.', 'BRAC4002.3c_ROI3_MRTX.',\n",
        "        'BRAC3529.2b_ROI1_MRTX_crop2.', 'BRAC4002.3c_ROI1_MRTX.']\n",
        "    cutoff - \n",
        "    \"\"\"\n",
        "    \n",
        "    full2 = pd.read_csv(path+'20210413_ContMRTX_neighbour_clustering_61clusters_DCsSeparated_TCrenamed_addedInfo copy.csv')\n",
        "    full2_nandrop=full2.dropna()\n",
        "\n",
        "\n",
        "    le_domain = preprocessing.LabelEncoder()\n",
        "    full2_nandrop[label_output] = le_domain.fit_transform(full2_nandrop[label_output])\n",
        "\n",
        "    loc_all_cell = full2_nandrop[['Location_Center_X','Location_Center_Y']].to_numpy()\n",
        "\n",
        "    cols_to_drop=['X.1', 'X.2','X.3']\n",
        "\n",
        "    output_df=full2_nandrop.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "    # data frame for each roi. can write function to do this, or create a dictionary   \n",
        "\n",
        "    output_df = output_df[(output_df.ROI_name==(roi))]\n",
        "    output_df = output_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    loc_roi = output_df[['Location_Center_X','Location_Center_Y']].to_numpy()\n",
        "    \n",
        "\n",
        "    dist_1=distance_matrix(cutoff, loc_roi,loc_roi, 'coo_matrix')\n",
        "\n",
        "    data , row, col = dist_1.data ,dist_1.row, dist_1.col\n",
        "\n",
        "    def mini(x):\n",
        "        if x!=0.0: \n",
        "            return 1/x \n",
        "        else: return x\n",
        "\n",
        "    def mini2(x):\n",
        "        if x!=0.0: \n",
        "            return 1\n",
        "        else: return x\n",
        "\n",
        "    vfunc = np.vectorize(mini)\n",
        "    data1 = vfunc(data)\n",
        "    \n",
        "    n,_  = loc_roi.shape \n",
        "    adj = sp.coo_matrix((data1, (row, col)), shape=(n, n))\n",
        "\n",
        "    cols_to_drop = ['Location_Center_X','Location_Center_Y']\n",
        "    output_df=output_df.drop(cols_to_drop,axis=1)\n",
        "\n",
        "\n",
        "    labels = output_df[label_output].to_numpy()\n",
        "    features = output_df.drop(label_output,axis=1)\n",
        "\n",
        "    # indexes_to_encode = [2, 3, 21, 22, 23, 24, 55]\n",
        "\n",
        "    to_encode = ['cellID', 'cellType', 'Treatment', 'ROI_name', 'Filename', 'Clustername', 'clustername_tumour','Domain']\n",
        "\n",
        "    if label_output in to_encode: \n",
        "        to_encode.remove(label_output)\n",
        "\n",
        "    for col in to_encode: \n",
        "        le_domain = preprocessing.LabelEncoder()\n",
        "        features[col] = le_domain.fit_transform(features[col])\n",
        "        \n",
        "    features=features.to_numpy()\n",
        "    S=sp.csr_matrix(adj)\n",
        "\n",
        "    edge_index , edge_weight = from_scipy_sparse_matrix(S)\n",
        "\n",
        "    print(\"Data Loaded\")\n",
        "\n",
        "    return S, torch.tensor(features), torch.tensor(labels) , edge_index ,edge_weight\n",
        "\n",
        "\n",
        "\n",
        "def load_data_adjacency_clusters_with_greater_than_x(roi='BRAC4002.3c_ROI3_MRTX.', cutoff= 25, output='dict',label_output='cluster',cell_cutoff=200):\n",
        "\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    roi - required reigon of interest: \n",
        "    Valid  ROI's are: ['BRAC3495.3f_ROI1_Cont_crop1.', 'BRAC3495.3f_ROI1_Cont_crop2.',\n",
        "        'BRAC3326.4e_ROI1_Cont_crop1.', 'BRAC3438.6f_ROI1_Cont.',\n",
        "        'BRAC3438.6f_ROI2_Cont.', 'BRAC3438.6f_ROI3_Cont.', 'BRAC3529.2d_ROI1_MRTX.', 'BRAC4002.3c_ROI2_MRTX_crop1.',\n",
        "        'BRAC4002.3c_ROI2_MRTX_crop2.', 'BRAC4002.3c_ROI3_MRTX.',\n",
        "        'BRAC3529.2b_ROI1_MRTX_crop2.', 'BRAC4002.3c_ROI1_MRTX.']\n",
        "    cutoff - \n",
        "    \"\"\"\n",
        "    \n",
        "    full2 = pd.read_csv(path+'20210413_ContMRTX_neighbour_clustering_61clusters_DCsSeparated_TCrenamed_addedInfo copy.csv')\n",
        "    full2_nandrop=full2.dropna()\n",
        "\n",
        "\n",
        "    le_domain = preprocessing.LabelEncoder()\n",
        "    full2_nandrop[label_output] = le_domain.fit_transform(full2_nandrop[label_output])\n",
        "\n",
        "    loc_all_cell = full2_nandrop[['Location_Center_X','Location_Center_Y']].to_numpy()\n",
        "\n",
        "    cols_to_drop=['X.1', 'X.2','X.3']\n",
        "\n",
        "    t=full2_nandrop['cluster'].value_counts().to_frame()\n",
        "    valid_clusters=t[t>cell_cutoff].dropna().index\n",
        "    full2_nandrop=full2_nandrop[full2_nandrop['cluster'].isin(valid_clusters)]\n",
        "\n",
        "    output_df=full2_nandrop.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    # data frame for each roi. can write function to do this, or create a dictionary   \n",
        "\n",
        "    output_df = output_df[(output_df.ROI_name==(roi))]\n",
        "    output_df = output_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    loc_roi = output_df[['Location_Center_X','Location_Center_Y']].to_numpy()\n",
        "    \n",
        "\n",
        "    dist_1=distance_matrix(cutoff, loc_roi,loc_roi, 'coo_matrix')\n",
        "\n",
        "    data , row, col = dist_1.data ,dist_1.row, dist_1.col\n",
        "\n",
        "    def mini(x):\n",
        "        if x!=0.0: \n",
        "            return 1/x \n",
        "        else: return x\n",
        "\n",
        "    def mini2(x):\n",
        "        if x!=0.0: \n",
        "            return 1\n",
        "        else: return x\n",
        "\n",
        "    vfunc = np.vectorize(mini)\n",
        "    data1 = vfunc(data)\n",
        "    \n",
        "    n,_  = loc_roi.shape \n",
        "    adj = sp.coo_matrix((data1, (row, col)), shape=(n, n))\n",
        "\n",
        "    cols_to_drop = ['Location_Center_X','Location_Center_Y']\n",
        "    output_df=output_df.drop(cols_to_drop,axis=1)\n",
        "\n",
        "\n",
        "    labels = output_df[label_output].to_numpy()\n",
        "    features = output_df.drop(label_output,axis=1)\n",
        "\n",
        "    # indexes_to_encode = [2, 3, 21, 22, 23, 24, 55]\n",
        "\n",
        "    to_encode = ['cellID', 'cellType', 'Treatment', 'ROI_name', 'Filename', 'Clustername', 'clustername_tumour','Domain']\n",
        "\n",
        "    if label_output in to_encode: \n",
        "        to_encode.remove(label_output)\n",
        "\n",
        "    for col in to_encode: \n",
        "        le_domain = preprocessing.LabelEncoder()\n",
        "        features[col] = le_domain.fit_transform(features[col])\n",
        "        \n",
        "    features=features.to_numpy()\n",
        "\n",
        "    print(adj.shape,features.shape,labels.shape)\n",
        "\n",
        "    S=sp.csr_matrix(adj)\n",
        "\n",
        "    edge_index , edge_weight = from_scipy_sparse_matrix(S)\n",
        "\n",
        "    print(\"Data Loaded\")\n",
        "\n",
        "    return S, torch.tensor(features), torch.tensor(labels) , edge_index ,edge_weight\n",
        "\n",
        "\n",
        "def load_data_adjacency_n_greatest_clusters(roi='BRAC4002.3c_ROI3_MRTX.', cutoff= 25, output='dict',label_output='cluster',n_clusters=20):\n",
        "\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    roi - required reigon of interest: \n",
        "    Valid  ROI's are: ['BRAC3495.3f_ROI1_Cont_crop1.', 'BRAC3495.3f_ROI1_Cont_crop2.',\n",
        "        'BRAC3326.4e_ROI1_Cont_crop1.', 'BRAC3438.6f_ROI1_Cont.',\n",
        "        'BRAC3438.6f_ROI2_Cont.', 'BRAC3438.6f_ROI3_Cont.', 'BRAC3529.2d_ROI1_MRTX.', 'BRAC4002.3c_ROI2_MRTX_crop1.',\n",
        "        'BRAC4002.3c_ROI2_MRTX_crop2.', 'BRAC4002.3c_ROI3_MRTX.',\n",
        "        'BRAC3529.2b_ROI1_MRTX_crop2.', 'BRAC4002.3c_ROI1_MRTX.']\n",
        "    cutoff - \n",
        "    \"\"\"\n",
        "    \n",
        "    full2 = pd.read_csv(path+'20210413_ContMRTX_neighbour_clustering_61clusters_DCsSeparated_TCrenamed_addedInfo copy.csv')\n",
        "    full2_nandrop=full2.dropna()\n",
        "\n",
        "\n",
        "    le_domain = preprocessing.LabelEncoder()\n",
        "    full2_nandrop[label_output] = le_domain.fit_transform(full2_nandrop[label_output])\n",
        "\n",
        "    loc_all_cell = full2_nandrop[['Location_Center_X','Location_Center_Y']].to_numpy()\n",
        "\n",
        "    cols_to_drop=['X.1', 'X.2','X.3']\n",
        "\n",
        "    t=full2_nandrop['cluster'].value_counts().to_frame()\n",
        "    valid_clusters=t.nlargest(n_clusters,'cluster').index\n",
        "    full2_nandrop=full2_nandrop[full2_nandrop['cluster'].isin( valid_clusters)]\n",
        "\n",
        "    output_df=full2_nandrop.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "    # data frame for each roi. can write function to do this, or create a dictionary   \n",
        "\n",
        "    output_df = output_df[(output_df.ROI_name==(roi))]\n",
        "    output_df = output_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    loc_roi = output_df[['Location_Center_X','Location_Center_Y']].to_numpy()\n",
        "    \n",
        "\n",
        "    dist_1=distance_matrix(cutoff, loc_roi,loc_roi, 'coo_matrix')\n",
        "\n",
        "    data , row, col = dist_1.data ,dist_1.row, dist_1.col\n",
        "\n",
        "    def mini(x):\n",
        "        if x!=0.0: \n",
        "            return 1/x \n",
        "        else: return x\n",
        "\n",
        "    def mini2(x):\n",
        "        if x!=0.0: \n",
        "            return 1\n",
        "        else: return x\n",
        "\n",
        "    vfunc = np.vectorize(mini)\n",
        "    data1 = vfunc(data)\n",
        "    \n",
        "    n,_  = loc_roi.shape \n",
        "    adj = sp.coo_matrix((data1, (row, col)), shape=(n, n))\n",
        "\n",
        "    cols_to_drop = ['Location_Center_X','Location_Center_Y']\n",
        "    output_df=output_df.drop(cols_to_drop,axis=1)\n",
        "\n",
        "\n",
        "    labels = output_df[label_output].to_numpy()\n",
        "    features = output_df.drop(label_output,axis=1)\n",
        "\n",
        "    # indexes_to_encode = [2, 3, 21, 22, 23, 24, 55]\n",
        "\n",
        "    to_encode = ['cellID', 'cellType', 'Treatment', 'ROI_name', 'Filename', 'Clustername', 'clustername_tumour','Domain']\n",
        "\n",
        "    if label_output in to_encode: \n",
        "        to_encode.remove(label_output)\n",
        "\n",
        "    for col in to_encode: \n",
        "        le_domain = preprocessing.LabelEncoder()\n",
        "        features[col] = le_domain.fit_transform(features[col])\n",
        "        \n",
        "    features=features.to_numpy()\n",
        "\n",
        "    print(adj.shape,features.shape,labels.shape)\n",
        "\n",
        "    S=sp.csr_matrix(adj)\n",
        "\n",
        "    edge_index , edge_weight = from_scipy_sparse_matrix(S)\n",
        "\n",
        "    print(\"Data Loaded\")\n",
        "\n",
        "    return S, torch.tensor(features), torch.tensor(labels) , edge_index ,edge_weight\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyNz5IGZx1Rz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZPkEPdTumxH"
      },
      "source": [
        "Main model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6rHI3TKun_W"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "dropout=0.5\n",
        "epochs=50\n",
        "hidden_dim=64\n",
        "lr = 0.1\n",
        "weight_decay=0.0005\n",
        "t_factor=1\n",
        "values=[]\n",
        "plot_accuracy = False\n",
        "roi = 'BRAC3529.2b_ROI1_MRTX_crop2.'\n",
        "label_output = 'cluster'\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "adj, features, labels , edge_index , edge_weight = load_data_adjacency(roi,cutoff=40,label_output=label_output)\n",
        "\n",
        "\n",
        "n = labels.shape[0]\n",
        "\n",
        "idx_train = range((int(np.floor(0.7*n)))) \n",
        "idx_val = range((int(np.floor(0.7*n))), (int(np.floor(0.8*n))))\n",
        "idx_test = range((int(np.floor(0.8*n))), (int(np.floor(1*n))))\n",
        "\n",
        "# print(idx_train,idx_val,idx_test)\n",
        "\n",
        "\n",
        "model = GCN(features.shape[1],\n",
        "            hidden_dim,\n",
        "            labels.max().item() + 1,\n",
        "            dropout)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# optimizer = torch.optim.Adam([\n",
        "#     dict(params=model.gc1.parameters(), weight_decay=weight_decay),\n",
        "#     dict(params=model.gc2.parameters(), weight_decay=0),\n",
        "#     dict(params=model.gc3.parameters(), weight_decay=0)\n",
        "# ], lr=0.01)\n",
        "\n",
        "print(\"Training the model\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "#     print('features/adj',features,adj)\n",
        "\n",
        "    output = model(features.float(), edge_index, edge_weight)\n",
        "\n",
        "    loss_train = F.cross_entropy(output[idx_train], labels[idx_train])\n",
        "    \n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    loss_val = F.cross_entropy(output[idx_val], labels[idx_val])\n",
        "\n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "    values.append(acc_train.item())\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "            'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "            'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "            'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "            'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "            'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "\"Testing the model\"\n",
        "\n",
        "model.eval()\n",
        "output = model(features.float(), edge_index, edge_weight)\n",
        "loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "\n",
        "print(\"Test set results:\",\n",
        "        \"loss= {:.4f}\".format(loss_test.item()),\n",
        "        \"accuracy= {:.4f}\".format(acc_test.item()))\n",
        "\n",
        "if plot_accuracy:\n",
        "    plt.plot(values)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Epochs: {epochs}, ROI: {roi} , 3 layer GCN: (Relu,Sigmoid,log_softmax), Test Accuracy: {acc_test}, Output: {label_output}\")\n",
        "    plt.savefig(f'plots/20 largest clusters , Epochs: {epochs}, ROI: {roi} , 3 layer GCN: (Relu,sigmoid,log_softmax), Test Accuracy: {acc_test}, Output: {label_output}.png')\n",
        "    # plt.show()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}